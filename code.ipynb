{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.50.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Using cached matplotlib-3.8.3-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Using cached contourpy-1.2.0-cp310-cp310-macosx_11_0_arm64.whl (242 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.50.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.50.0 kiwisolver-1.4.5 matplotlib-3.8.3 pillow-10.2.0 pyparsing-3.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install contractions\n",
    "# %pip install bs4\n",
    "# %pip install nltk\n",
    "# %pip install unidecode\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import nltk\n",
    "import contractions\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# from acronym import Acronym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Df loading function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  folder = parse(path)\n",
    "  for d in folder:\n",
    "    print(i)\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getDF('Electronics_5.json.gz')\n",
    "data_frame = pd.DataFrame.from_dict(df, orient='index')\n",
    "data_frame.to_csv('data_frame.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getDF('meta_Electronics.json.gz')\n",
    "meta_df = pd.DataFrame.from_dict(df, orient='index')\n",
    "meta_df.to_csv('meta_data.csv', index=False, escapechar='\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/kjgrgc293tn7cn556xk1h1g40000gn/T/ipykernel_15093/1755724970.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data_frame.csv\")\n",
      "/var/folders/4f/kjgrgc293tn7cn556xk1h1g40000gn/T/ipykernel_15093/1755724970.py:2: DtypeWarning: Columns (3,6,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  meta_data = pd.read_csv(\"meta_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data_frame.csv\")\n",
    "meta_data = pd.read_csv(\"meta_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14310"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_indices = []\n",
    "product = 'USB Cables'\n",
    "for i in range(len(meta_data)):\n",
    "    if product in meta_data['category'][i]:\n",
    "        product_indices.append(i)\n",
    "\n",
    "product_meta_data_df = meta_data.iloc[product_indices]\n",
    "product_meta_data_df = product_meta_data_df.dropna(subset=['title', 'asin'])\n",
    "product_meta_data_df = product_meta_data_df.drop_duplicates()\n",
    "\n",
    "product_df= pd.merge(data, product_meta_data_df, on='asin', how='inner')\n",
    "product_df = product_df.dropna(subset=['overall'])\n",
    "product_df = product_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expand_acronyms(text):\n",
    "    expanded_words = []    \n",
    "    for word in text.split():\n",
    "        expanded_words.append(contractions.fix(word))  \n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    return expanded_text\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "def remove_accented_chars(text):\n",
    "    return unidecode(text)\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    return preprocessed_text\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = expand_acronyms(text)\n",
    "    text = remove_html_tags(text)\n",
    "    text = remove_accented_chars(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text\n",
    "\n",
    "product_df['reviewText'] = product_df['reviewText'].astype(str)\n",
    "for i in range(len(product_df)):\n",
    "    print(i)\n",
    "    pre_text =  normalize_text(product_df['reviewText'].iloc[i])\n",
    "    product_df.loc[i, \"reviewText\"]=pre_text\n",
    "    \n",
    "product_df.to_csv('product.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124237 entries, 0 to 124236\n",
      "Data columns (total 30 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   overall          120806 non-null  float64\n",
      " 1   vote             7329 non-null    object \n",
      " 2   verified         120806 non-null  object \n",
      " 3   reviewTime       120806 non-null  object \n",
      " 4   reviewerID       120806 non-null  object \n",
      " 5   asin             120806 non-null  object \n",
      " 6   style            68955 non-null   object \n",
      " 7   reviewerName     120775 non-null  object \n",
      " 8   reviewText       124146 non-null  object \n",
      " 9   summary          120784 non-null  object \n",
      " 10  unixReviewTime   120806 non-null  float64\n",
      " 11  image            1181 non-null    object \n",
      " 12  category         120806 non-null  object \n",
      " 13  tech1            51449 non-null   object \n",
      " 14  description      120806 non-null  object \n",
      " 15  fit              0 non-null       float64\n",
      " 16  title            120806 non-null  object \n",
      " 17  also_buy         120806 non-null  object \n",
      " 18  tech2            1949 non-null    object \n",
      " 19  brand            120722 non-null  object \n",
      " 20  feature          120806 non-null  object \n",
      " 21  rank             120806 non-null  object \n",
      " 22  also_view        120806 non-null  object \n",
      " 23  main_cat         120796 non-null  object \n",
      " 24  similar_item     91557 non-null   object \n",
      " 25  date             92585 non-null   object \n",
      " 26  price            85748 non-null   object \n",
      " 27  imageURL         120806 non-null  object \n",
      " 28  imageURLHighRes  120806 non-null  object \n",
      " 29  details          120806 non-null  object \n",
      "dtypes: float64(3), object(27)\n",
      "memory usage: 28.4+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/kjgrgc293tn7cn556xk1h1g40000gn/T/ipykernel_16371/896985281.py:1: DtypeWarning: Columns (1,2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  product_df = pd.read_csv(\"product.csv\")\n"
     ]
    }
   ],
   "source": [
    "product_df = pd.read_csv(\"product.csv\")\n",
    "product_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " . Number of rows for the product: 124237\n",
      "a. Number of Reviews: 124146\n",
      "b. Average Rating Score: 4.365503369037961\n",
      "c. Number of Unique Products: 2591\n",
      "d. Number of Good Ratings: 107710\n",
      "e. Number of Bad Ratings: 13096\n",
      "f. Number of Reviews corresponding to each Rating:\n",
      "overall\n",
      "1.0     8621\n",
      "2.0     4475\n",
      "3.0     6809\n",
      "4.0    15124\n",
      "5.0    85777\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_reviews = product_df['reviewText'].count()\n",
    "average_rating = product_df['overall'].mean()\n",
    "num_unique_products = product_df['asin'].nunique()\n",
    "good_ratings = product_df[product_df['overall'] >= 3]['overall'].count()\n",
    "bad_ratings = product_df[product_df['overall'] < 3]['overall'].count()\n",
    "rating_counts = product_df['overall'].value_counts().sort_index()\n",
    "\n",
    "# Display the results\n",
    "print(\" . Number of rows for the product:\", len(product_df))\n",
    "print(\"a. Number of Reviews:\", total_reviews)\n",
    "print(\"b. Average Rating Score:\", average_rating)\n",
    "print(\"c. Number of Unique Products:\", num_unique_products)\n",
    "print(\"d. Number of Good Ratings:\", good_ratings)\n",
    "print(\"e. Number of Bad Ratings:\", bad_ratings)\n",
    "print(\"f. Number of Reviews corresponding to each Rating:\")\n",
    "print(rating_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tqdm\n",
    "\n",
    "# Raise all warnings as exceptions\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wordcloud(text_list, title):\n",
    "    text = ' '.join(text_list)\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = None, \n",
    "                min_font_size = 10).generate(text)\n",
    "\n",
    "    # Plot the WordCloud image                        \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    plt.title(title)\n",
    "  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most positively reviewed headphone:\n",
      "title\n",
      "Myron &amp; Davis AE52 Dual Channel IR headphone    5.0\n",
      "Name: overall, dtype: float64\n",
      "a. Top 20 most reviewed brands:\n",
      "brand\n",
      "Sony              31260\n",
      "Sennheiser        21221\n",
      "Bose               9489\n",
      "Plantronics        8239\n",
      "Skullcandy         7862\n",
      "JVC                7024\n",
      "JLAB               6977\n",
      "Audio-Technica     6651\n",
      "Philips            6458\n",
      "Panasonic          5980\n",
      "Koss               5764\n",
      "Mpow               5643\n",
      "LG                 5624\n",
      "Samsung            5597\n",
      "Bluedio            5364\n",
      "MEE audio          4644\n",
      "Anker              4291\n",
      "Symphonized        4285\n",
      "TaoTronics         4056\n",
      "Beats              3993\n",
      "Name: count, dtype: int64\n",
      "Top 20 least reviewed brands:\n",
      "brand\n",
      "EMPIRE AUDIO USA         5\n",
      "Cosa Nova                5\n",
      "MAXELL(R)                5\n",
      "OAproda                  5\n",
      "TomTom                   5\n",
      "tech21                   5\n",
      "SoulBuddy                5\n",
      "fizwan                   5\n",
      "OCR                      5\n",
      "Spark                    5\n",
      "VIILER                   5\n",
      "YooZoo                   4\n",
      "DetectorPro              4\n",
      "SOUND-SQUARED CO.        4\n",
      "NOIZY Brands             3\n",
      "DSI                      3\n",
      "Zelco Industries, Inc    3\n",
      "Fred & Friends           3\n",
      "Digital Antenna          1\n",
      "Honda                    1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_20_most_reviewed_brands = product_df['brand'].value_counts().head(20)\n",
    "top_20_least_reviewed_brands = product_df['brand'].value_counts().tail(20)\n",
    "most_positively_reviewed_headphone = product_df.groupby('title')['overall'].mean().nlargest(1)\n",
    "\n",
    "\n",
    "print(\"a. Top 20 most reviewed brands:\")\n",
    "print(top_20_most_reviewed_brands)\n",
    "print(\"b. Top 20 least reviewed brands:\")\n",
    "print(top_20_least_reviewed_brands)\n",
    "print(\"c. Most positively reviewed headphone:\")\n",
    "print(most_positively_reviewed_headphone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(product_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4f/kjgrgc293tn7cn556xk1h1g40000gn/T/ipykernel_3520/1072341768.py:3: FutureWarning: 'Y' is deprecated and will be removed in a future version, please use 'YE' instead.\n",
      "  ratings_over_years = product_df.set_index('date').groupby(pd.Grouper(freq='Y')).size().head(5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of ratings for the product over 5 consecutive years:\n",
      "date\n",
      "1973-12-31    129\n",
      "1974-12-31      0\n",
      "1975-12-31      0\n",
      "1976-12-31      0\n",
      "1977-12-31      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "product_df['date'] = pd.to_datetime(product_df['date'], errors='coerce')\n",
    "# Count of ratings for the product over 5 consecutive years\n",
    "ratings_over_years = product_df.set_index('date').groupby(pd.Grouper(freq='Y')).size().head(5)\n",
    "print(\"Count of ratings for the product over 5 consecutive years:\")\n",
    "print(ratings_over_years)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
